<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Andrea Simonelli</title>
  
  <meta name="author" content="Andrea Simonelli">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Andrea Simonelli</name>
              </p>
              <p>
                I am a 2nd year PhD student at the University of Trento (Italy), co-funded by Mapillary and Fondazione Bruno Kessler (FBK). My advisors are prof. Elisa Ricci (UniTn) and dr. Samuel Rota Bulo' (Facebook).
              </p>

              <p>
                I received the bachelor and master degree (summa cum laude) from the University of Trento in 2015 and 2018, respectively. During my PhD I collaborate both with Mapillary Research (led by dr. Peter Kontschieder) and the Technologies of Vision group (led by dr. Stefano Messelodi) at FBK. Being co-funded by research as well as industry organizations I take part to both research and industrial projects, having the great opportunity not only to develop novel solutions but also to apply them to real-world scenarios. 
              </p>

              <p>
                My research is focused on Machine Learning and Computer Vision. In particular, I have been tackling the 3D Object Detection task in the Monocular and RGB-only setting.
              </p>

              <p style="text-align:center">
                <a href="mailto:simonelli.andrea23@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=wK2I1ZsAAAAJ&hl=en">Google Scholar</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/andrea.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/andrea.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/virtviews.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1912.08035">
                <papertitle>Towards Generalization Across Depth for Monocular 3D Object Detection</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=xf1T870AAAAJ&hl=en">Elisa Ricci</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>
              <br>
        <em>ECCV</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/1912.08035">arXiv</a>
              <p>We propose to perform the detection, instead of on the usual full-resolution image, on a series of Virtual Views. Virtual Views make the appearence of the objects invariant with respect to distance, easing the overall task. We also propose a single-stage, lightweight architecture called MoVi-3D. We achieve state-of-the-art results on the popular KITTI3D benchmark.</p>
            </td>
          </tr>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/pami.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Disentangling Monocular 3D Object Detection: From Single to Multi-Class Recognition</papertitle>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=I-t1ZrYAAAAJ&hl=en">Manuel Lòpez Antequera</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>
              <br>
        <em>TPAMI</em>, 2020  
              <br>
              <p>We extend our previous ICCV19 work to the multi-class scenario. In particular, we apply the MonoDIS detector to the challenging nuScenes dataset, achieving comparable results with a LiDAR baseline. In this work we also report updated scores on KITTI3D. </p>
            </td>
          </tr>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/3ddet.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1905.12365">
                <papertitle>Disentangling Monocular 3D Object Detection</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=I-t1ZrYAAAAJ&hl=en">Manuel Lòpez Antequera</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>
              <br>
        <em>ICCV</em>, 2019  
              <br>
              <a href="https://arxiv.org/abs/1905.12365">arXiv</a>
              <p>We propose a disentangling transformation which simplifies the training dynamics in the presence of losses with complex interactions of parameters, sidestepping the issue of balancing independent regression terms. We also propose a self-supervised 3D confidence which is very useful to understand the quality of the predicted 3D bounding boxes. In addition, we resolve a flaw in the (now deprecated) KITTI3D metric which affected all the previously published results. Our proposed metric is now the official KITTI3D metric, used to evaluate all methods on the KITTI3D benchmark.</p>
            </td>
          </tr>


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/icip.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8451097/">
                <papertitle>Increasingly specialized ensemble of convolutional neural networks for fine-grained recognition</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=Js5-wwcAAAAJ&hl=en">Francesco De Natale</a>,
              <a href="https://scholar.google.com/citations?user=ptAz-SwAAAAJ&hl=en">Stefano Messelodi</a>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>
              <br>
        <em>ICIP</em>, 2018 (Oral presentation)
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/8451097/">IEEEXplore</a>
              <p>We propose a simple method for fine-grained recognition that exploits a nearly cost-free attention-based focus operation to construct an ensemble of increasingly specialized Convolutional Neural Networks.</p>
            </td>
          </tr>

    
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            </td>
            <td width="75%" valign="center">
              <a href="https://www.nuscenes.org/object-detection?externalData=all&mapData=all&modalities=Any">Winner team of the nuScenes 3D Object Detection Challenge Camera Track, CVPR 2019</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/unitn.png" width="150" height="100"></td>
            <td width="75%" valign="center">
              <p>Student Merit Award, 2018</p>
              <p>Student Merit Award, 2015</p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/unitn.png" width="150" height="100"></td>
            <td width="75%" valign="center">
              <p>Advanced Algorithms Teaching Assistant, prof. Elisa Ricci and dr. Samuel Rota Bulò, Spring 2020</p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                The source code for this website has been taken from <a href="https://github.com/jonbarron/jonbarron_website"> this</a> nice repo.
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
